## Стратегия обновления Blue/Green
Сине-зеленое развертывание **Kubernetes** (иногда называемое красным/черным) предполагает развертывание новой версии вместе со старой. Внутренняя команда QA может тестировать новую версию (синий цвет), в то время как клиент продолжает получать доступ к старой версии (зеленый цвет). После тестирования и утверждения релиза трафик можно перенаправить на новую версию (синий цвет), изменив сервис Kubernetes. После этого, когда разработчики будут уверены в работоспособности релиза, старая версия (зеленая) может быть уменьшена до нуля.

![Kubernetes Deployments](./assets/k8s-deployments-blue-green.gif)
Эта стратегия также гарантирует отсутствие простоев в работе клиентов во время развертывания, а также дает бизнесу дополнительный уровень уверенности в новом сервисе (по результатам QA-тестирования). Синяя/зеленая стратегии предполагают больше инженерных работ и являются самыми затратными с точки зрения ресурсов (удвоение ресурсов приложения), однако при необходимости старые версии могут быть немедленно развернуты.
Развертывание по схеме "сине-зеленый" является затратным, поскольку требует удвоения ресурсов. Прежде чем запускать платформу в промышленную эксплуатацию, необходимо провести надлежащее тестирование всей платформы. Кроме того, сложно работать с приложениями, имеющими состояние.

Сначала создадим нашу синюю установку, сохранив следующий yaml в файл 'blue.yaml':
<pre class="file" data-filename="./blue.yaml" data-target="replace">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: blue-deployment
spec:
  selector:
    matchLabels:
      app: blue-deployment
      version: nanoserver-1709
  replicas: 3
  template:
    metadata:
      labels:
        app: blue-deployment
        version: nanoserver-1709
    spec:
      containers:
        - name: blue-deployment
          image: hello-world:nanoserver-1709
</pre>
И применим манифест

`kubectl apply -f blue.yaml`{{execute T1}}

Далее мы зададим эти метки в качестве селектора меток для сервиса. Сохраним это в файле service.yaml.
<pre class="file" data-filename="./service.yaml" data-target="replace">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: blue-deployment
spec:
  selector:
    matchLabels:
      app: blue-deployment
      version: nanoserver-1709
  replicas: 3
  template:
    metadata:
      labels:
        app: blue-deployment
        version: nanoserver-1709
    spec:
      containers:
        - name: blue-deployment
          image: hello-world:nanoserver-1709
</pre>
Теперь при создании службы будет создан балансировщик нагрузки, доступный вне кластера.
`kubectl apply -f service.yaml`{{execute T1}}

Для зеленого развертывания мы развернем новое развертывание параллельно с синим развертыванием. Приведенный ниже шаблон является содержимым файла green.yaml:
<pre class="file" data-filename="./green.yaml" data-target="replace">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: green-deployment
spec:
  selector:
    matchLabels:
      app: green-deployment
      version: nanoserver-1809
  replicas: 3
  template:
    metadata:
      labels:
        app: green-deployment
        version: nanoserver-1809
    spec:
      containers:
        - name: green-deployment
          image: hello-world:nanoserver-1809
</pre>

Применим манифест
`kubectl apply -f green.yaml`{{execute T1}}

Далее мы зададим эти метки в качестве селектора меток для сервиса. Сохраним это в файле service.yaml.
<pre class="file" data-filename="./service.yaml" data-target="replace">
apiVersion: v1
kind: Service
metadata: 
  name: blue-green-service
  labels: 
    name: green-deployment
    version: nanoserver-1809
spec:
  ports:
    - name: http
      port: 80
      targetPort: 80
  selector: 
    name: green-deployment
    version: nanoserver-1809
  type: LoadBalancer
</pre>
Теперь при создании службы будет создан балансировщик нагрузки, доступный вне кластера.
`kubectl apply -f service.yaml`{{execute T1}}

Состояние деплоймента можно получить с помощью команд:

`kubectl get deploy hello-deployment `{{execute T1}}

**Плюсы:**
- Мгновенное развертывание/откат.
- Отсутствие проблемы с версионностью, все состояние приложения изменяется за один раз.

**Минусы:**
- Дороговизна, поскольку требует удвоения ресурсов.
- Перед запуском в промышленную эксплуатацию необходимо провести надлежащее тестирование всей платформы.
- Работа с приложениями, имеющими состояние, может оказаться сложной.

## Стратегия обновления Canary
Развертывания **Canary** во многом схожи с развертываниями **blue/green**, с той лишь разницей, что новая версия приложения выпускается для небольшого подмножества клиентов. При этом небольшой процент трафика приложения направляется на новую версию, чтобы инженеры могли наблюдать за развертыванием, пока оно тестируется на реальных клиентах. После того как разработчики будут удовлетворены работой новой версии, они могут начать постепенно увеличивать объем трафика, направляемого на новую версию, пока весь трафик не будет направлен на новую версию. После этого старая версия уменьшается до нуля.

![Kubernetes Deployments](./assets/k8s-deployments-canary.gif)

Канареечное развертывание заключается в постепенном переводе производственного трафика с версии А на версию В. Обычно трафик делится по весу. Например, 90% запросов поступает на версию A, 10% - на версию B.
Этот метод чаще всего используется в тех случаях, когда тесты недостаточны или ненадежны, а также если нет уверенности в стабильности нового релиза на платформе.

При планировании развертывания **Canary** необходимо учитывать различные моменты:
- Этапы: сколько пользователей и сколько этапов мы планируем запустить "канарейку".
- Продолжительность: как долго мы планируем использовать canary? Релизы canary отличаются тем, что нам необходимо дождаться обновления достаточного количества клиентов, прежде чем мы сможем оценить результаты. Это может происходить в течение нескольких дней или даже недель.
- Метрики: какие метрики необходимо регистрировать для анализа прогресса, включая производительность приложения и отчеты об ошибках? Хорошо подобранные параметры очень важны для успешного развертывания канарейки. Например, очень простым способом оценки развертывания являются коды состояния HTTP. Мы можем иметь простую службу ping, которая при успешном развертывании возвращает 200. При возникновении проблем с развертыванием он будет возвращать ошибку конца сервера (5xx).
- Оценка: какие критерии мы будем использовать для определения успешности работы канарейки

Наш первый файл, stable.yaml, будет представлять собой устаревшую версию, на которой будет работать большинство наших подсистем.
<pre class="file" data-filename="./stable.yaml" data-target="replace">
apiVersion: apps/v1
kind: Deployment
metadata:
  name: helloworld
spec:
  replicas: 3
  strategy:
    rollingUpdate:
    maxSurge: 1
    maxUnavailable: 1
  minReadySeconds: 5
  template:
    metadata:
      labels:
        app: helloworld
        track: stable
    spec:
      containers:
      - name: helloworld
        image: educative/helloworld:1.0
        ports:
        - containerPort: 80
        resources:
          requests:
            cpu: 50m
          limits:
            cpu: 100m
</pre>

В результате будет создано 3 Pods v1 с меткой app:helloworld, которую ищет наш сервис Kubernetes. Наш образ для этих Pod'ов - educative/helloworld:1.0, что означает, что эти Pod'ы будут созданы на основе старых спецификаций Pod'ов.

Это развертывание равномерно распределит любую рабочую нагрузку между доступными Pod.

Для развертывания необходимо ввести в командную строку следующую строку:
`kubectl apply -f stable.yaml`{{execute T1}}

Состояние деплоймента можно получить с помощью команд:

`kubectl get deploy hello-deployment `{{execute T1}}

**Плюсы:**
- Версия, выпущенная для подмножества пользователей.
- Удобна для мониторинга количества ошибок и производительности.
- Быстрый откат.

**Минусы:**
- Замедленное развертывание.


## Стратегия обновления A/B Testing
Канареечное развертывание заключается в постепенном переводе производственного трафика с версии А на версию В. Обычно трафик делится по весу. Например, 90% запросов поступает на версию A, 10% - на версию B.
Этот метод чаще всего используется в тех случаях, когда тесты недостаточны или ненадежны, а также если нет уверенности в стабильности нового релиза на платформе.

![Kubernetes Deployments](./assets/k8s-deployments-a-b.gif)


**Плюсы:**
- Простота настройки.
- Постепенное распространение версий по всем экземплярам.
- Удобно для приложений с состоянием, которые обеспечивают перераспределение данных.

**Минусы:**
- Откат/переход может занимать время.
- Поддержка нескольких API затруднена.
- Отсутствие контроля над трафиком.

## Стратегия обновления Shadow
Канареечное развертывание заключается в постепенном переводе производственного трафика с версии А на версию В. Обычно трафик делится по весу. Например, 90% запросов поступает на версию A, 10% - на версию B.
Этот метод чаще всего используется в тех случаях, когда тесты недостаточны или ненадежны, а также если нет уверенности в стабильности нового релиза на платформе.

![Kubernetes Deployments](./assets/k8s-deployments-shadow.gif)


**Плюсы:**
- Простота настройки.
- Постепенное распространение версий по всем экземплярам.
- Удобно для приложений с состоянием, которые обеспечивают перераспределение данных.

**Минусы:**
- Откат/переход может занимать время.
- Поддержка нескольких API затруднена.
- Отсутствие контроля над трафиком.
